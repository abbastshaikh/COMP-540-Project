{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from util import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../data/imputed.csv')\n",
    "target = ['EURWH_MBOE','OilEURWH_MBBL','GasEURWH_BCF']\n",
    "\n",
    "X = data[[column for column in data.columns if column not in target]]\n",
    "y = data['EURWH_MBOE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 519.4715650973463\n",
      "Mean NRMSE: 0.4908922307604242\n",
      "Mean Adjusted R^2: 0.39171923426434524\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "predictions = cross_validate(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with alpha = 0.01\n",
      "Mean RMSE: 519.4715232802155\n",
      "Mean NRMSE: 0.49089219158713043\n",
      "Mean Adjusted R^2: 0.39171933362820827\n",
      "\n",
      "Evaluating model with alpha = 0.1\n",
      "Mean RMSE: 519.4711478565829\n",
      "Mean NRMSE: 0.49089183990065893\n",
      "Mean Adjusted R^2: 0.39172022568627696\n",
      "\n",
      "Evaluating model with alpha = 1\n",
      "Mean RMSE: 519.467483742307\n",
      "Mean NRMSE: 0.490888407599593\n",
      "Mean Adjusted R^2: 0.39172893158251576\n",
      "\n",
      "Evaluating model with alpha = 10\n",
      "Mean RMSE: 519.4382282350982\n",
      "Mean NRMSE: 0.4908610132668542\n",
      "Mean Adjusted R^2: 0.3917983976849318\n",
      "\n",
      "Evaluating model with alpha = 100\n",
      "Mean RMSE: 519.3871543227492\n",
      "Mean NRMSE: 0.49081343426810486\n",
      "Mean Adjusted R^2: 0.3919188351946744\n",
      "\n",
      "Evaluating model with alpha = 1000\n",
      "Mean RMSE: 520.9817190365195\n",
      "Mean NRMSE: 0.492319251433546\n",
      "Mean Adjusted R^2: 0.3881672024395911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "for alpha in [1e-2, 1e-1, 1, 10, 100, 1000]:\n",
    "    model = Ridge(alpha = alpha)\n",
    "    print(\"Evaluating model with alpha =\", alpha)\n",
    "    predictions = cross_validate(model, X, y)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with alpha = 0.1\n",
      "Mean RMSE: 519.4441786337054\n",
      "Mean NRMSE: 0.49086665626466247\n",
      "Mean Adjusted R^2: 0.39178723082657996\n",
      "\n",
      "Evaluating model with alpha = 1\n",
      "Mean RMSE: 519.424883169093\n",
      "Mean NRMSE: 0.4908477957086627\n",
      "Mean Adjusted R^2: 0.39183681758405003\n",
      "\n",
      "Evaluating model with alpha = 10\n",
      "Mean RMSE: 523.8801770994944\n",
      "Mean NRMSE: 0.49505923743201014\n",
      "Mean Adjusted R^2: 0.38134864202269453\n",
      "\n",
      "Evaluating model with alpha = 100\n",
      "Mean RMSE: 575.2585347425963\n",
      "Mean NRMSE: 0.5436718445900082\n",
      "Mean Adjusted R^2: 0.25364397978234554\n",
      "\n",
      "Evaluating model with alpha = 1000\n",
      "Mean RMSE: 666.8020881572897\n",
      "Mean NRMSE: 0.6302410686315301\n",
      "Mean Adjusted R^2: -0.0036927883122761075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for alpha in [1e-1, 1, 10, 100, 1000]:\n",
    "    model = Lasso(alpha = alpha)\n",
    "    print(\"Evaluating model with alpha =\", alpha)\n",
    "    predictions = cross_validate(model, X, y)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with n estimators = 100 and max depth = 5\n",
      "Mean RMSE: 513.4321666512012\n",
      "Mean NRMSE: 0.4852101796416882\n",
      "Mean Adjusted R^2: 0.4055213633943498\n",
      "\n",
      "Evaluating model with n estimators = 100 and max depth = 10\n",
      "Mean RMSE: 474.4652836312689\n",
      "Mean NRMSE: 0.4483637162912134\n",
      "Mean Adjusted R^2: 0.4923435240898799\n",
      "\n",
      "Evaluating model with n estimators = 250 and max depth = 5\n",
      "Mean RMSE: 513.5883846946176\n",
      "Mean NRMSE: 0.4853605095295051\n",
      "Mean Adjusted R^2: 0.4051530959080873\n",
      "\n",
      "Evaluating model with n estimators = 250 and max depth = 10\n",
      "Mean RMSE: 474.39991320295314\n",
      "Mean NRMSE: 0.4482923209901471\n",
      "Mean Adjusted R^2: 0.49250913513552164\n",
      "\n",
      "Evaluating model with n estimators = 500 and max depth = 5\n",
      "Mean RMSE: 513.6064844763553\n",
      "Mean NRMSE: 0.4853783496833385\n",
      "Mean Adjusted R^2: 0.4051142903852343\n",
      "\n",
      "Evaluating model with n estimators = 500 and max depth = 10\n",
      "Mean RMSE: 473.3875077854723\n",
      "Mean NRMSE: 0.4473385550732334\n",
      "Mean Adjusted R^2: 0.49466814201739656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "for n_estimators in [100, 250, 500]:\n",
    "    for max_depth in [5, 10]:\n",
    "        print(\"Evaluating model with n estimators =\", n_estimators, \"and max depth =\", max_depth)\n",
    "        model = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth)\n",
    "        predictions = cross_validate(model, X, y)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with n estimators = 100 and no max depth.\n",
      "Mean RMSE: 452.90260722877656\n",
      "Mean NRMSE: 0.4279659026697905\n",
      "Mean Adjusted R^2: 0.5373938564864448\n",
      "\n",
      "Evaluating model with n estimators = 250 and no max depth.\n",
      "Mean RMSE: 451.17339650047245\n",
      "Mean NRMSE: 0.42633124771171615\n",
      "Mean Adjusted R^2: 0.5410033418042046\n",
      "\n",
      "Evaluating model with n estimators = 500 and no max depth.\n",
      "Fold: 6\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mathw\\Desktop\\College\\Fall 23\\COMP 540\\Project\\COMP-540-Project\\code\\base_models.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathw/Desktop/College/Fall%2023/COMP%20540/Project/COMP-540-Project/code/base_models.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEvaluating model with n estimators =\u001b[39m\u001b[39m\"\u001b[39m, n_estimators, \u001b[39m\"\u001b[39m\u001b[39mand no max depth.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathw/Desktop/College/Fall%2023/COMP%20540/Project/COMP-540-Project/code/base_models.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m RandomForestRegressor(n_estimators \u001b[39m=\u001b[39m n_estimators)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mathw/Desktop/College/Fall%2023/COMP%20540/Project/COMP-540-Project/code/base_models.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m predictions \u001b[39m=\u001b[39m cross_validate(model, X, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathw/Desktop/College/Fall%2023/COMP%20540/Project/COMP-540-Project/code/base_models.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\mathw\\Desktop\\College\\Fall 23\\COMP 540\\Project\\COMP-540-Project\\code\\util.py:20\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(model, X, y)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFold:\u001b[39m\u001b[39m\"\u001b[39m, i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, end \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[train_index], X\u001b[39m.\u001b[39miloc[test_index], y\u001b[39m.\u001b[39miloc[train_index], y\u001b[39m.\u001b[39miloc[test_index]\n\u001b[1;32m---> 20\u001b[0m pipeline\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     21\u001b[0m pred \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     23\u001b[0m rmse\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39msqrt(((y_test \u001b[39m-\u001b[39m pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean()))\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthreads\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39mcurr_sample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39mbuild(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "for n_estimators in [100, 250, 500]:\n",
    "    print(\"Evaluating model with n estimators =\", n_estimators, \"and no max depth.\")\n",
    "    model = RandomForestRegressor(n_estimators = n_estimators)\n",
    "    predictions = cross_validate(model, X, y)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with n estimators = 100 , learning rate = 0.01 , max depth =  5\n",
      "Mean RMSE: 533.0568941269072\n",
      "Mean NRMSE: 0.5037600291593229\n",
      "Mean Adjusted R^2: 0.3593582743610112\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 0.01 , max depth =  10\n",
      "Mean RMSE: 526.9627973959795\n",
      "Mean NRMSE: 0.49799218751120744\n",
      "Mean Adjusted R^2: 0.3739330481758871\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 0.01 , max depth =  -1\n",
      "Mean RMSE: 527.0482196933202\n",
      "Mean NRMSE: 0.49807256747946926\n",
      "Mean Adjusted R^2: 0.3737211737901768\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 0.1 , max depth =  5\n",
      "Mean RMSE: 463.1925069155379\n",
      "Mean NRMSE: 0.43771926665917055\n",
      "Mean Adjusted R^2: 0.5161890096130414\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 0.1 , max depth =  10\n",
      "Mean RMSE: 456.8237154448916\n",
      "Mean NRMSE: 0.43168869444814195\n",
      "Mean Adjusted R^2: 0.5293525094439764\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 0.1 , max depth =  -1\n",
      "Mean RMSE: 456.9200502169789\n",
      "Mean NRMSE: 0.4317619275470704\n",
      "Mean Adjusted R^2: 0.5291286215430061\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 1 , max depth =  5\n",
      "Mean RMSE: 550.3836264774131\n",
      "Mean NRMSE: 0.5201670466200522\n",
      "Mean Adjusted R^2: 0.31649334137397955\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 1 , max depth =  10\n",
      "Mean RMSE: 577.1035620140585\n",
      "Mean NRMSE: 0.545515409073494\n",
      "Mean Adjusted R^2: 0.24765546148192485\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 1 , max depth =  -1\n",
      "Mean RMSE: 580.5925140533597\n",
      "Mean NRMSE: 0.5487348396725551\n",
      "Mean Adjusted R^2: 0.2387728074839517\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 0.01 , max depth =  5\n",
      "Mean RMSE: 490.0117995454657\n",
      "Mean NRMSE: 0.46306115157400896\n",
      "Mean Adjusted R^2: 0.4586647829801119\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 0.01 , max depth =  10\n",
      "Mean RMSE: 481.9752789915259\n",
      "Mean NRMSE: 0.4554534132050817\n",
      "Mean Adjusted R^2: 0.47624350921935105\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 0.01 , max depth =  -1\n",
      "Mean RMSE: 481.98530569350186\n",
      "Mean NRMSE: 0.4554675951206777\n",
      "Mean Adjusted R^2: 0.47622018111322556\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 0.1 , max depth =  5\n",
      "Mean RMSE: 454.8608315741182\n",
      "Mean NRMSE: 0.42983634366630685\n",
      "Mean Adjusted R^2: 0.5334197412871211\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 0.1 , max depth =  10\n",
      "Mean RMSE: 450.896462408523\n",
      "Mean NRMSE: 0.42608865598622075\n",
      "Mean Adjusted R^2: 0.5414259690569853\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 0.1 , max depth =  -1\n",
      "Mean RMSE: 451.1421181754119\n",
      "Mean NRMSE: 0.42632043947116866\n",
      "Mean Adjusted R^2: 0.5408696097222935\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 1 , max depth =  5\n",
      "Mean RMSE: 577.451851346879\n",
      "Mean NRMSE: 0.5457452610095002\n",
      "Mean Adjusted R^2: 0.24767952602360888\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 1 , max depth =  10\n",
      "Mean RMSE: 597.0654131081762\n",
      "Mean NRMSE: 0.5643407935118891\n",
      "Mean Adjusted R^2: 0.19475628346787893\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 1 , max depth =  -1\n",
      "Mean RMSE: 603.3503561717638\n",
      "Mean NRMSE: 0.5702726155257729\n",
      "Mean Adjusted R^2: 0.17745764398248806\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 0.01 , max depth =  5\n",
      "Mean RMSE: 473.2396885276189\n",
      "Mean NRMSE: 0.4472055139935657\n",
      "Mean Adjusted R^2: 0.49501440404376035\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 0.01 , max depth =  10\n",
      "Mean RMSE: 463.2327099610044\n",
      "Mean NRMSE: 0.43773210202467194\n",
      "Mean Adjusted R^2: 0.5160893327013925\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 0.01 , max depth =  -1\n",
      "Mean RMSE: 463.29355001819766\n",
      "Mean NRMSE: 0.43779123517279145\n",
      "Mean Adjusted R^2: 0.5159511421921708\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 0.1 , max depth =  5\n",
      "Mean RMSE: 452.1150821757251\n",
      "Mean NRMSE: 0.4272359411375932\n",
      "Mean Adjusted R^2: 0.5390172282611159\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 0.1 , max depth =  10\n",
      "Mean RMSE: 449.6123022589888\n",
      "Mean NRMSE: 0.42487813819454806\n",
      "Mean Adjusted R^2: 0.5439629888649875\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 0.1 , max depth =  -1\n",
      "Mean RMSE: 449.6988458762697\n",
      "Mean NRMSE: 0.4249521470826165\n",
      "Mean Adjusted R^2: 0.5437805841927795\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 1 , max depth =  5\n",
      "Mean RMSE: 588.9578715770979\n",
      "Mean NRMSE: 0.5566436581239125\n",
      "Mean Adjusted R^2: 0.21720263418521166\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 1 , max depth =  10\n",
      "Mean RMSE: 600.8353666479723\n",
      "Mean NRMSE: 0.5679111548860601\n",
      "Mean Adjusted R^2: 0.18446759441115218\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 1 , max depth =  -1\n",
      "Mean RMSE: 606.8777793819742\n",
      "Mean NRMSE: 0.5736083990378076\n",
      "Mean Adjusted R^2: 0.1677282615029006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "for n_estimators in [100, 250, 500]:\n",
    "    for learning_rate in [1e-2, 1e-1, 1]:\n",
    "        for max_depth in [5, 10, -1]:\n",
    "            print(\"Evaluating model with n estimators =\", n_estimators, \", learning rate =\", learning_rate, \", max depth = \", max_depth)\n",
    "            model = LGBMRegressor(n_estimators = n_estimators, learning_rate = learning_rate, max_depth = max_depth, force_col_wise=True, verbose=-1)\n",
    "            predictions = cross_validate(model, X, y)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with n estimators = 100 , learning rate = 0.01 , max depth =  5\n",
      "Mean RMSE: 533.5513335400916\n",
      "Mean NRMSE: 0.5042281002563878\n",
      "Mean Adjusted R^2: 0.3581504913337007\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 0.01 , max depth =  10\n",
      "Mean RMSE: 505.0705884996939\n",
      "Mean NRMSE: 0.4772804029637746\n",
      "Mean Adjusted R^2: 0.42501345168019194\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 0.1 , max depth =  5\n",
      "Mean RMSE: 465.54486575861273\n",
      "Mean NRMSE: 0.43994580294519736\n",
      "Mean Adjusted R^2: 0.5113389724952138\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 0.1 , max depth =  10\n",
      "Mean RMSE: 451.0848837747424\n",
      "Mean NRMSE: 0.426230932019146\n",
      "Mean Adjusted R^2: 0.54112996605766\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 1 , max depth =  5\n",
      "Mean RMSE: 559.3117669981004\n",
      "Mean NRMSE: 0.528397743920753\n",
      "Mean Adjusted R^2: 0.2932433258407404\n",
      "\n",
      "Evaluating model with n estimators = 100 , learning rate = 1 , max depth =  10\n",
      "Mean RMSE: 583.0109919295626\n",
      "Mean NRMSE: 0.5509352275599272\n",
      "Mean Adjusted R^2: 0.2328587583817102\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 0.01 , max depth =  5\n",
      "Mean RMSE: 491.37698128362524\n",
      "Mean NRMSE: 0.46435516448725067\n",
      "Mean Adjusted R^2: 0.4556430687697578\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 0.01 , max depth =  10\n",
      "Mean RMSE: 462.20092236382436\n",
      "Mean NRMSE: 0.43673947069265784\n",
      "Mean Adjusted R^2: 0.5183865154792279\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 0.1 , max depth =  5\n",
      "Mean RMSE: 456.35215502781665\n",
      "Mean NRMSE: 0.43126846205028696\n",
      "Mean Adjusted R^2: 0.5304316214005355\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 0.1 , max depth =  10\n",
      "Mean RMSE: 450.9192786328769\n",
      "Mean NRMSE: 0.4260840012708799\n",
      "Mean Adjusted R^2: 0.5414389408744256\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 1 , max depth =  5\n",
      "Mean RMSE: 579.4287059605699\n",
      "Mean NRMSE: 0.5473853438818597\n",
      "Mean Adjusted R^2: 0.2415096561776826\n",
      "\n",
      "Evaluating model with n estimators = 250 , learning rate = 1 , max depth =  10\n",
      "Mean RMSE: 583.009207219549\n",
      "Mean NRMSE: 0.550933458739299\n",
      "Mean Adjusted R^2: 0.23286287292800872\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 0.01 , max depth =  5\n",
      "Mean RMSE: 474.87940984283216\n",
      "Mean NRMSE: 0.44876052475717654\n",
      "Mean Adjusted R^2: 0.49149872778152026\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 0.01 , max depth =  10\n",
      "Mean RMSE: 453.3489280418041\n",
      "Mean NRMSE: 0.42837966204033295\n",
      "Mean Adjusted R^2: 0.5364981149164365\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 0.1 , max depth =  5\n",
      "Mean RMSE: 453.93336476849515\n",
      "Mean NRMSE: 0.42896505654146866\n",
      "Mean Adjusted R^2: 0.5354541556623561\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 0.1 , max depth =  10\n",
      "Mean RMSE: 450.9041673988325\n",
      "Mean NRMSE: 0.4260737925295784\n",
      "Mean Adjusted R^2: 0.5414731361837706\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 1 , max depth =  5\n",
      "Mean RMSE: 584.5589262985114\n",
      "Mean NRMSE: 0.5522321765726539\n",
      "Mean Adjusted R^2: 0.22809374813679692\n",
      "\n",
      "Evaluating model with n estimators = 500 , learning rate = 1 , max depth =  10\n",
      "Mean RMSE: 583.0092055969553\n",
      "Mean NRMSE: 0.5509334571922719\n",
      "Mean Adjusted R^2: 0.23286287714912207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "for n_estimators in [100, 250, 500]:\n",
    "    for learning_rate in [1e-2, 1e-1, 1]:\n",
    "        for max_depth in [5, 10]:\n",
    "            print(\"Evaluating model with n estimators =\", n_estimators, \", learning rate =\", learning_rate, \", max depth = \", max_depth)\n",
    "            model = XGBRegressor(n_estimators = n_estimators, learning_rate = learning_rate, max_depth = max_depth)\n",
    "            predictions = cross_validate(model, X, y)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with kernel = rbf , C = 1\n",
      "Mean RMSE: 613.1975335514837\n",
      "Mean NRMSE: 0.5794708068806337\n",
      "Mean Adjusted R^2: 0.151842402127845\n",
      "\n",
      "Evaluating model with kernel = rbf , C = 10\n",
      "Mean RMSE: 536.3809681633078\n",
      "Mean NRMSE: 0.5068165058828301\n",
      "Mean Adjusted R^2: 0.3514853022143085\n",
      "\n",
      "Evaluating model with kernel = rbf , C = 100\n",
      "Mean RMSE: 494.9361286941321\n",
      "Mean NRMSE: 0.4676568107288356\n",
      "Mean Adjusted R^2: 0.44790348557060355\n",
      "\n",
      "Evaluating model with kernel = linear , C = 1\n",
      "Mean RMSE: 525.3467721214191\n",
      "Mean NRMSE: 0.4964229902878737\n",
      "Mean Adjusted R^2: 0.37788753497027494\n",
      "\n",
      "Evaluating model with kernel = linear , C = 10\n",
      "Mean RMSE: 524.921496798095\n",
      "Mean NRMSE: 0.4960175085403863\n",
      "Mean Adjusted R^2: 0.37889057179224633\n",
      "\n",
      "Evaluating model with kernel = linear , C = 100\n",
      "Mean RMSE: 525.1319692143801\n",
      "Mean NRMSE: 0.4962146512259113\n",
      "Mean Adjusted R^2: 0.378390965700613\n",
      "\n",
      "Evaluating model with kernel = polynomial , C = 1\n",
      "Fold: 1\r"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'kernel' parameter of SVR must be a str among {'linear', 'precomputed', 'rbf', 'poly', 'sigmoid'} or a callable. Got 'polynomial' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mathw\\Desktop\\College\\Fall 23\\COMP 540\\Project\\COMP-540-Project\\code\\base_models.ipynb Cell 9\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathw/Desktop/College/Fall%2023/COMP%20540/Project/COMP-540-Project/code/base_models.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEvaluating model with kernel =\u001b[39m\u001b[39m\"\u001b[39m, kernel, \u001b[39m\"\u001b[39m\u001b[39m, C =\u001b[39m\u001b[39m\"\u001b[39m, C)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathw/Desktop/College/Fall%2023/COMP%20540/Project/COMP-540-Project/code/base_models.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m SVR(kernel \u001b[39m=\u001b[39m kernel, C \u001b[39m=\u001b[39m C)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mathw/Desktop/College/Fall%2023/COMP%20540/Project/COMP-540-Project/code/base_models.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m predictions \u001b[39m=\u001b[39m cross_validate(model, X, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathw/Desktop/College/Fall%2023/COMP%20540/Project/COMP-540-Project/code/base_models.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\mathw\\Desktop\\College\\Fall 23\\COMP 540\\Project\\COMP-540-Project\\code\\util.py:20\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(model, X, y)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFold:\u001b[39m\u001b[39m\"\u001b[39m, i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, end \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[train_index], X\u001b[39m.\u001b[39miloc[test_index], y\u001b[39m.\u001b[39miloc[train_index], y\u001b[39m.\u001b[39miloc[test_index]\n\u001b[1;32m---> 20\u001b[0m pipeline\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     21\u001b[0m pred \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     23\u001b[0m rmse\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39msqrt(((y_test \u001b[39m-\u001b[39m pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean()))\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\sklearn\\svm\\_base.py:180\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    148\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the SVM model according to the given training data.\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \n\u001b[0;32m    150\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39m    matrices as input.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m    182\u001b[0m     rnd \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[0;32m    184\u001b[0m     sparse \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39misspmatrix(X)\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\sklearn\\base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    593\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    594\u001b[0m \n\u001b[0;32m    595\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 600\u001b[0m     validate_parameter_constraints(\n\u001b[0;32m    601\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parameter_constraints,\n\u001b[0;32m    602\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m    603\u001b[0m         caller_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m,\n\u001b[0;32m    604\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mathw\\anaconda3\\envs\\COMP540\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:97\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[0;32m     93\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m     )\n\u001b[1;32m---> 97\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     98\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'kernel' parameter of SVR must be a str among {'linear', 'precomputed', 'rbf', 'poly', 'sigmoid'} or a callable. Got 'polynomial' instead."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "for kernel in ['rbf', 'linear', 'poly']:\n",
    "    for C in [1, 10, 100]:\n",
    "            print(\"Evaluating model with kernel =\", kernel, \", C =\", C)\n",
    "            model = SVR(kernel = kernel, C = C)\n",
    "            predictions = cross_validate(model, X, y)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with kernel = poly , C = 1\n",
      "Mean RMSE: 630.2832082598261\n",
      "Mean NRMSE: 0.595650642446912\n",
      "Mean Adjusted R^2: 0.10358961072947778\n",
      "\n",
      "Evaluating model with kernel = poly , C = 10\n",
      "Mean RMSE: 562.2627879879828\n",
      "Mean NRMSE: 0.5313265129804331\n",
      "Mean Adjusted R^2: 0.2870583864080281\n",
      "\n",
      "Evaluating model with kernel = poly , C = 100\n",
      "Mean RMSE: 531.6520094197416\n",
      "Mean NRMSE: 0.502339918342152\n",
      "Mean Adjusted R^2: 0.35894784809051505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for kernel in ['poly']:\n",
    "    for C in [1, 10, 100]:\n",
    "            print(\"Evaluating model with kernel =\", kernel, \", C =\", C)\n",
    "            model = SVR(kernel = kernel, C = C)\n",
    "            predictions = cross_validate(model, X, y)\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP540",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
